# GAN

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601022120468.png" alt="image-20250601022120468" style="zoom: 33%;" />

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601021929271.png" alt="image-20250601021929271" style="zoom: 33%;" />

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601021949811.png" alt="image-20250601021949811" style="zoom: 33%;" />

GAN在生成图像的多样性上很有保证，但随机性主要来源于生成器输入的随机分布

GAN不直接建模数据的概率分布，而是通过一个可微分的生成器网络隐式地学习分布特性

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601022422132.png" alt="image-20250601022422132" style="zoom: 33%;" />

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601022459800.png" alt="image-20250601022459800" style="zoom: 33%;" />

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601022523621.png" alt="image-20250601022523621" style="zoom:33%;" />

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601022557340.png" alt="image-20250601022557340" style="zoom: 33%;" />

# VAE

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601142908134.png" alt="image-20250601142908134" style="zoom:33%;" />

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601143153203.png" alt="image-20250601143153203" style="zoom:50%;" />

Auto-encoder-decoder结构中bottleneck学习到的特征仅用于重建，很难进行随机性的表征

VAE假设在encoder与decoder间学习的是一个多维的高斯分布，不同维度的分布表示不同的概念，在多维高斯分布内随机采样

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601153950414.png" alt="image-20250601153950414" style="zoom: 33%;" />

VQVAE中将输入的编码与保存了K个向量（聚类中心）的codebook进行比对，取出对应向量进行解码（离散量化更有助于优化）

codebook向量不是随机生成的，可用于边缘检测、分割等下游任务，但进行生成任务还需要另加prior网络（VQVAE）

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601160111058.png" alt="image-20250601160111058" style="zoom:33%;" />

# DALL.E

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601155845477.png" alt="image-20250601155845477" style="zoom: 33%;" />

DALL.E 将text通过BPE进行编码，image通过训练好的VQVAE编码，将图像与文本的编码连接后交给GPT进行自回归的预测

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601205146721.png" alt="image-20250601205146721" style="zoom:33%;" />

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601205216860.png" alt="image-20250601205216860" style="zoom:33%;" />

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601205236711.png" alt="image-20250601205236711" style="zoom:33%;" />

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601205255024.png" alt="image-20250601205255024" style="zoom:33%;" />

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601205349739.png" alt="image-20250601205349739" style="zoom:33%;" />

# Diffusion

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601160306750.png" alt="image-20250601160306750" style="zoom:33%;" />

前向扩散：向图片里逐步加上高斯噪声，当步数足够大时图片最终就会变成各相同性的高斯噪声

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601160433925.png" alt="image-20250601160433925" style="zoom:33%;" />

反向扩散：对加噪声的图片一步步去噪

DDPM在还原时不预测前一步图像，而是预测这一步添加的噪声，前向扩散时添加的噪声可以作为 ground truth 辅助网络训练

DDPM还发现在VQVAE学习的多维高斯分布中只学习均值就能有很好的效果（方差只需要是一个常数值），简化优化过程

在反向过程中加 time_embedding 告知还原到了哪一步（u-net还原过程中所有步数上的模型共享参数）

# U-Net

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601163645816.png" alt="image-20250601163645816" style="zoom: 25%;" />

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601163838875.png" alt="image-20250601163838875" style="zoom: 50%;" />

以CNN形式为例，左半编码器部分每次对图像进行卷积+池化的下采样，同时通道数加倍

右半的解码器部分每次对图像进行卷积的上采样，同时通道数减半（转置卷积即通过插值扩大图像）

中间的连接将编码器特征直接复制到解码器通道上面进行叠加，从底部的bottleneck开始从下采样转为上采样



<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601163352216.png" alt="image-20250601163352216" style="zoom:33%;" />

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601171922811.png" alt="image-20250601171922811" style="zoom:25%;" />

在经过u-net进行反向传播的过程中将带噪声图片经过图像分类器，用分类器的梯度信息指导采样与后续的去噪生成

分类器在一个带噪声的图片数据集上进行提前训练（提升图片写实性）（classifier guided diffusion）

将classifier替换为CLIP就可以使用文本去定向引导图像的生成方向

<img src="C:\Users\11241\AppData\Roaming\Typora\typora-user-images\image-20250601172627402.png" alt="image-20250601172627402" style="zoom:33%;" />

classifier guidance free 生成方法在训练时产生带文本指示与不带文本指示的输出，使模型大概清楚两种条件下的差距，在生成时引导